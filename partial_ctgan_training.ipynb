# function responsible for synthesizing base data
def run_instance(run_config: RunConfig):

    model_id = run_config.model_id

    train_df = run_config.train_df # assignment of training dataframe
    val_df = run_config.val_df # assignment of validation dataframe
    discrete_columns = run_config.discrete_columns # record of discrete columns in data

    model_run_dir = pathlib.Path(run_config.model_run_dir) # experimental results directory

    config = run_config.config
    config_save_path = config_path(model_run_dir, model_id) # accessing configuration file
    model_save_path = model_path(model_run_dir, model_id) # specific model location within experimental results directory
    model_evaluation_save_path = model_evaluation_path(model_run_dir, model_id) # model evaluation results
    train_data_save_path = train_dataset_path(model_run_dir, model_id) # training dataset location
    synthetic_data_save_path = synthetic_dataset_path(model_run_dir, model_id) # synthetic data location

    run_stdout_path = stdout_path(model_run_dir, model_id)
    run_stderr_path = stderr_path(model_run_dir, model_id)

    seed = run_config.seed # random seed for reproducibility

    # status information
    logging.info('Model %s: Training started', pad_int(model_id))
    logging.debug('Model %s: Config %s', pad_int(model_id), config)
    logging.debug('Model %s: Saved config to \'%s\'', pad_int(model_id), config_save_path)
    logging.debug('Model %s: Stdout redirected to \'%s\'', pad_int(model_id), run_stdout_path)
    logging.debug('Model %s: Stderr redirected to \'%s\'', pad_int(model_id), run_stderr_path)

    data_config = config['data'] # location for training, validation datasets, and column names
    model_config = config['model'] # model kwargs parameters


    df = pd.concat((train_df, val_df)) # concatenation of training and validation dataframes
    df = utils.shuffle(df) # shuffling concatenated dataframe

    df = apply_config_to_data(df, data_config, model_id, seed) # applying configuration parameters to dataframe

    discrete_columns = copy.copy(discrete_columns)

    metadata_obj = SingleTableMetadata() # creation of metadata object necessary for synthesization library
    metadata_obj.detect_from_dataframe(df) # reading metadata information from dataframe

    os.mkdir(model_run_dir) # creation of experimental results directory

    df.to_csv(train_data_save_path) # saving training dataframe
    logging.debug('Model %s: Training data saved to %s', pad_int(model_id), train_data_save_path)

    # reading configuration file
    with open(config_save_path, 'w') as fd:
        yaml.safe_dump(config, stream=fd, default_flow_style=False)

    # CTGAN synthesizer model declaration
    model = CTGANSynthesizer(metadata=metadata_obj, **model_config)

    # fitting synthesizer model to training dataframe
    with open(run_stdout_path, 'w') as out_fd, open(run_stderr_path, 'w') as err_fd:
        with redirect_stdout(out_fd), redirect_stderr(err_fd):
            #model.fit(df, discrete_columns)
            model.fit(df)

    # saving CTGAN model
    model.save(model_save_path)

    logging.info('Model %s: Saved model to \'%s\'', pad_int(model_id), model_save_path)

    # conversion of synthetic dataframe to csv, then saving
    synthetic_df = model.sample(len(df))
    synthetic_df.to_csv(synthetic_data_save_path)

    logging.info('Model %s: Saved synthetic dataset to \'%s\'', pad_int(model_id), synthetic_data_save_path)

    return model_id, synthetic_df
