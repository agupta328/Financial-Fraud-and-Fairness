{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyOoL/odM1O4jpo2Dz/9ts7b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install aequitas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nnpJfnRkWvl","executionInfo":{"status":"ok","timestamp":1690988647661,"user_tz":300,"elapsed":40472,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"0274814f-e67b-48bc-fd27-fd28a5e39af1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting aequitas\n","  Downloading aequitas-0.42.0-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ohio>=0.2.0 (from aequitas)\n","  Downloading ohio-0.5.0-py3-none-any.whl (26 kB)\n","Collecting Flask==0.12.2 (from aequitas)\n","  Downloading Flask-0.12.2-py2.py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Flask-Bootstrap==3.3.7.1 (from aequitas)\n","  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting markdown2==2.3.5 (from aequitas)\n","  Downloading markdown2-2.3.5.zip (161 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from aequitas) (3.7.1)\n","Requirement already satisfied: pandas>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.5.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (2.0.19)\n","Collecting tabulate==0.8.2 (from aequitas)\n","  Downloading tabulate-0.8.2.tar.gz (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting xhtml2pdf==0.2.2 (from aequitas)\n","  Downloading xhtml2pdf-0.2.2.tar.gz (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.12.2)\n","Collecting altair==4.1.0 (from aequitas)\n","  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.8/727.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting millify==0.1.1 (from aequitas)\n","  Downloading millify-0.1.1.tar.gz (1.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.1.0->aequitas) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.1.0->aequitas) (3.1.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from altair==4.1.0->aequitas) (4.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair==4.1.0->aequitas) (1.22.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.1.0->aequitas) (0.12.0)\n","Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.10/dist-packages (from Flask==0.12.2->aequitas) (2.3.6)\n","Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask==0.12.2->aequitas) (8.1.6)\n","Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.10/dist-packages (from Flask==0.12.2->aequitas) (2.1.2)\n","Collecting dominate (from Flask-Bootstrap==3.3.7.1->aequitas)\n","  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n","Collecting visitor (from Flask-Bootstrap==3.3.7.1->aequitas)\n","  Downloading visitor-0.1.3.tar.gz (3.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: html5lib>=1.0 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.2->aequitas) (1.1)\n","Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.2->aequitas) (0.21.0)\n","Collecting pyPdf2 (from xhtml2pdf==0.2.2->aequitas)\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.2->aequitas) (9.4.0)\n","Collecting reportlab>=3.0 (from xhtml2pdf==0.2.2->aequitas)\n","  Downloading reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.2->aequitas) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.1->aequitas) (2022.7.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.1.1->aequitas) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.1.1->aequitas) (2.0.2)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0->xhtml2pdf==0.2.2->aequitas) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair==4.1.0->aequitas) (2.1.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->altair==4.1.0->aequitas) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->altair==4.1.0->aequitas) (0.19.3)\n","Building wheels for collected packages: Flask-Bootstrap, markdown2, millify, tabulate, xhtml2pdf, visitor\n","  Building wheel for Flask-Bootstrap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Flask-Bootstrap: filename=Flask_Bootstrap-3.3.7.1-py3-none-any.whl size=460123 sha256=88d38afb3bc66cd2161354414e8cbead92af813d1767fb85bc3a5b30142d9377\n","  Stored in directory: /root/.cache/pip/wheels/6f/33/ad/26540e84a28334e5dfeda756df270f95353779f03bc5cf40d4\n","  Building wheel for markdown2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for markdown2: filename=markdown2-2.3.5-py3-none-any.whl size=33325 sha256=960da5e450ae67df433290968f39f1cd078ebbf995a17e8907508293779b85ec\n","  Stored in directory: /root/.cache/pip/wheels/64/94/a9/15f2d5685178e7a61701b5f852d2230dcd3a420e4316f8c29c\n","  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1843 sha256=d33a728956daf9912d0e8074dd63a9faca48554ad3d8c3950c9994fbdc6bd4d8\n","  Stored in directory: /root/.cache/pip/wheels/67/8f/53/2759feac2e247ce89c1165c3ff12d484de7714a875ea3464f0\n","  Building wheel for tabulate (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tabulate: filename=tabulate-0.8.2-py3-none-any.whl size=23531 sha256=5d40efb153a5284390132e7f066c2a6ce6347f8186d6f2c3ef426f8b615ebf64\n","  Stored in directory: /root/.cache/pip/wheels/3a/eb/ae/5ae59ba76a9b078413b15eac159e56df2a51e4b1c10d44d099\n","  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.2-py3-none-any.whl size=233888 sha256=9a1d3a6b87fdd12a53056d66d69b3a217f27ba1242203623480cef9c02d527b9\n","  Stored in directory: /root/.cache/pip/wheels/ef/12/14/2cb8ea69b717deb63fbbc1f4a3220b702929c2c90d01ab513b\n","  Building wheel for visitor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visitor: filename=visitor-0.1.3-py3-none-any.whl size=3925 sha256=acb617dd321459ea9010d1728418761647495989589a7491079759797f34bd48\n","  Stored in directory: /root/.cache/pip/wheels/19/31/99/2ec5b4459cac4d801d6201d501a354366d180afc9f8bb2d333\n","Successfully built Flask-Bootstrap markdown2 millify tabulate xhtml2pdf visitor\n","Installing collected packages: visitor, tabulate, ohio, millify, markdown2, reportlab, pyPdf2, dominate, xhtml2pdf, Flask, Flask-Bootstrap, altair, aequitas\n","  Attempting uninstall: tabulate\n","    Found existing installation: tabulate 0.9.0\n","    Uninstalling tabulate-0.9.0:\n","      Successfully uninstalled tabulate-0.9.0\n","  Attempting uninstall: Flask\n","    Found existing installation: Flask 2.2.5\n","    Uninstalling Flask-2.2.5:\n","      Successfully uninstalled Flask-2.2.5\n","  Attempting uninstall: altair\n","    Found existing installation: altair 4.2.2\n","    Uninstalling altair-4.2.2:\n","      Successfully uninstalled altair-4.2.2\n","Successfully installed Flask-0.12.2 Flask-Bootstrap-3.3.7.1 aequitas-0.42.0 altair-4.1.0 dominate-2.8.0 markdown2-2.3.5 millify-0.1.1 ohio-0.5.0 pyPdf2-3.0.1 reportlab-4.0.4 tabulate-0.8.2 visitor-0.1.3 xhtml2pdf-0.2.2\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","import copy\n","import numpy as np       # Random number generation\n","import seaborn as sns    # Plotting library\n","import pandas as pd      # Read/write data\n","from aequitas.group import Group                # Fairness metrics\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt     # Plotting method\n","from sklearn.preprocessing import LabelEncoder  # Categorical encoding for LGBM models\n","from sklearn import metrics                     # ROC metrics\n","from sklearn.ensemble import RandomForestClassifier"],"metadata":{"id":"Z27ASYt4WKR1","executionInfo":{"status":"ok","timestamp":1690988652925,"user_tz":300,"elapsed":5268,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9T83-cfZ8Ou","executionInfo":{"status":"ok","timestamp":1690988653583,"user_tz":300,"elapsed":661,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"0b8b52ee-172c-4283-97d9-bfd92257d5e0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"grPTQBln6QEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690988671803,"user_tz":300,"elapsed":16444,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"8bea91c4-ebe3-4622-c747-72be2f9852a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/ECE697/Project/random_search.py ."],"metadata":{"id":"lrfNScboXjFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from random_search import RandomValueTrial, suggest_callable_hyperparams  # Random search wrapper methods"],"metadata":{"id":"n59U6w7dXlrQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define path to datasets. Replace `base_path` with the appropriate value.\n","base_path = \"/content/drive/MyDrive/Colab Notebooks/ECE697/Project/Income Data Variants 1m/\"\n","\n","datasets_paths = {\n","    \"TypeI\":   base_path + \"income_07_type1.csv\",\n","    \"TypeII\":  base_path + \"income_07_type2.csv\",\n","    \"TypeIII\": base_path + \"income_07_type3.csv\",\n","    \"TypeIV\":  base_path + \"income_07_type4.csv\",\n","    \"TypeV\":   base_path + \"income_07_type5.csv\",\n","    \"TypeVI\":  base_path + \"income_07_type6.csv\"\n"," }"],"metadata":{"id":"_WyROh15XpIx","executionInfo":{"status":"ok","timestamp":1690988673967,"user_tz":300,"elapsed":215,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Read the datasets with pandas.\n","datasets = {key: pd.read_csv(path,usecols=range(1,33)) for key, path in datasets_paths.items()}"],"metadata":{"id":"nm-kdB9IXsKG","executionInfo":{"status":"ok","timestamp":1690988713479,"user_tz":300,"elapsed":37118,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Define the label field and categorical columns.\n","label = \"fraud_bool\"\n","\n","categorical_features = [\n","    \"payment_type\",\n","    \"employment_status\",\n","    \"housing_status\",\n","    \"source\",\n","    \"device_os\",\n","]"],"metadata":{"id":"q2I5aYFoXt0H","executionInfo":{"status":"ok","timestamp":1690988713480,"user_tz":300,"elapsed":20,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Create the train and test sets. Shuffle data with `sample` method.\n","# The split was done by month. The first 6 months as the train, the last 2 months as test.\n","train_dfs = {key: df[df[\"month\"]<6].sample(frac=1, replace=False) for key, df in datasets.items()}\n","test_dfs = {key: df[df[\"month\"]>=6].sample(frac=1, replace=False) for key, df in datasets.items()}"],"metadata":{"id":"Pc-eLf00Xv-C","executionInfo":{"status":"ok","timestamp":1690988716306,"user_tz":300,"elapsed":2844,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Encode the categorical variables in the datasets to integers.\n","# This is expected by LGBM (or columns with the `categorical` data type).\n","\n","for name in datasets.keys():  # For each dataset in the suite\n","    train = train_dfs[name]\n","    test = test_dfs[name]\n","\n","    for feat in categorical_features:\n","        encoder = LabelEncoder()\n","        encoder.fit(train[feat])  # Fit an encoder to the train set.\n","        train[feat] = encoder.transform(train[feat])  # Transform train set.\n","        test[feat] = encoder.transform(test[feat])    # Transform test set."],"metadata":{"id":"WetN0X33e105","executionInfo":{"status":"ok","timestamp":1690988722326,"user_tz":300,"elapsed":6024,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["METRICS = [\n","      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n","      keras.metrics.MeanSquaredError(name='Brier score'),\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'),\n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","]\n","\n","def make_model(metrics=METRICS, output_bias=None, train_feat_shape=train_dfs[\"TypeI\"].shape[-1]):\n","  if output_bias is not None:\n","    output_bias = tf.keras.initializers.Constant(output_bias)\n","  model = keras.Sequential([\n","      keras.layers.Dense(\n","          16, activation='tanh',\n","          input_shape=(train_feat_shape,)),\n","      keras.layers.Dense(16, activation='tanh'),\n","      #keras.layers.Dropout(0.3),\n","      keras.layers.Dense(16, activation='tanh'),\n","      #keras.layers.Dropout(0.5),\n","      keras.layers.Dense(1, activation='sigmoid',\n","                         bias_initializer=output_bias),\n","  ])\n","\n","  model.compile(\n","      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","      loss=keras.losses.BinaryCrossentropy(),\n","      metrics=metrics)\n","\n","  return model"],"metadata":{"id":"7of2Wca0kRoH","executionInfo":{"status":"ok","timestamp":1690995780646,"user_tz":300,"elapsed":3,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 100\n","BATCH_SIZE = 2048\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_prc',\n","    verbose=1,\n","    patience=10,\n","    mode='max',\n","    restore_best_weights=True)"],"metadata":{"id":"GPJv_xTikYT0","executionInfo":{"status":"ok","timestamp":1690995782707,"user_tz":300,"elapsed":2,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["model = make_model()\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rpjN0DE3kaid","executionInfo":{"status":"ok","timestamp":1690995783697,"user_tz":300,"elapsed":7,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"f23478b9-129d-4866-8281-f248c3239523"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_24 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_25 (Dense)            (None, 16)                272       \n","                                                                 \n"," dense_26 (Dense)            (None, 16)                272       \n","                                                                 \n"," dense_27 (Dense)            (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 1,089\n","Trainable params: 1,089\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def plot_cm(labels, predictions, threshold=0.5):\n","  cm = metrics.confusion_matrix(labels, predictions > threshold)\n","  plt.figure(figsize=(5,5))\n","  sns.heatmap(cm, annot=True, fmt=\"d\")\n","  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n","  plt.ylabel('Actual label')\n","  plt.xlabel('Predicted label')\n","\n","  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n","  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n","  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n","  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n","  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"],"metadata":{"id":"mzq-XFU1xnj3","executionInfo":{"status":"ok","timestamp":1690995786675,"user_tz":300,"elapsed":1,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Cell with train loop.\n","\n","# Define number of trials in Random search.\n","n_trials=100\n","# Random state for sampling seeds.\n","np.random.seed(42)\n","# Seeds for the random search sampling algorithm.\n","seeds = np.random.choice(list(range(1_000_000)), size=n_trials, replace=False)\n","\n","EPOCHS = 200\n","BATCH_SIZE = 2048\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_prc',\n","    verbose=1,\n","    patience=10,\n","    mode='max',\n","    restore_best_weights=True)\n","\n","# Variable to store the results.\n","runs = {}\n","tf_runs = {}\n","total_predictions = {}\n","\n","#for trial in range(n_trials):\n","    #seed = seeds[trial]\n","    #trial = RandomValueTrial(seed=seed)\n","    # Hyperparameters for the random search trial.\n","    #test_hyperparams = suggest_callable_hyperparams(trial, hyperparam_space)\n","    #del test_hyperparams[\"classpath\"] # Remove unnecessary key in hyperparaemters.\n","\n","    # Update list of tested hyperparameters.\n","    #prev_hyperparams = runs.get(\"hyperparams\", [])\n","    #prev_hyperparams.append(test_hyperparams)\n","    #runs[\"hyperparams\"] = prev_hyperparams\n","\n","\n","    # two tabs separation\n","for dataset_name in datasets.keys():  # Run hyperparameters on all variants of datastes.\n","    neg, pos = np.bincount(train_dfs[dataset_name]['fraud_bool'])\n","    total = neg + pos\n","    print('\\n\\n\\nExamples for {}:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n\\n\\n'.format(dataset_name, total, pos, 100 * pos / total))\n","    initial_bias = np.log([pos/neg])\n","\n","    X_train = train_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n","    y_train = train_dfs[dataset_name][\"fraud_bool\"]\n","    X_test = test_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n","    y_test = test_dfs[dataset_name][\"fraud_bool\"]\n","\n","    model = make_model(output_bias=initial_bias, train_feat_shape=X_train.shape[-1])\n","    # Fit model to training data.\n","    careful_bias_history = model.fit(\n","      X_train,\n","      y_train,\n","      batch_size=BATCH_SIZE,\n","      epochs=EPOCHS,\n","      verbose=0)\n","    # Obtain predictions in test data.\n","    predictions_direct = model.predict(X_test, batch_size=BATCH_SIZE)\n","    predictions = predictions_direct.tolist()\n","    predictions_evaluation = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n","\n","    tf_metric_results = {}\n","    for name, value in zip(model.metrics_names, predictions_evaluation):\n","      tf_metric_results[name] = value\n","    tf_runs[dataset_name] = tf_metric_results\n","\n","    total_predictions[dataset_name] = (y_test, predictions)\n","\n","    \"\"\"\n","\n","    # Obtain ROC curve for the predictions.\n","    fprs, tprs, thresholds = metrics.roc_curve(y_test, predictions)\n","    # Obtain threshold and recall. We select 5% FPR as threshold.\n","    threshold = np.min(thresholds[fprs==max(fprs[fprs < 0.05])])\n","    recall = np.max(tprs[fprs==max(fprs[fprs < 0.05])])\n","\n","    # Binarize predictions for Aequitas.\n","    preds_binary = (predictions > threshold).astype(int).tolist()\n","\n","    # Create a dataframe with protected group column, predictions and labels.\n","    # Here, we select income < 0.7 as threshold.\n","    aequitas_df = pd.DataFrame(\n","        {\n","            \"income\": (X_test[\"income\"] < 0.7).map({True: \"Minority\", False: \"Majority\"}),\n","             \"score\": preds_binary,\n","            \"label_value\": y_test.values\n","\n","        }\n","    )\n","\n","    # Obtain FPR results for different groups.\n","    g = Group()\n","    aequitas_results = g.get_crosstabs(aequitas_df, score_thresholds=None, attr_cols=[\"income\"])[0]  #,score_col=[\"preds\"], label_col=[\"y\"]\n","\n","    # Store the results for the trained model\n","    results = {}\n","    results[\"recall\"] = recall\n","    results[\"recall Minority\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Minority\"][[\"tpr\"]].values[0][0]\n","    results[\"recall Majority\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Majority\"][[\"tpr\"]].values[0][0]\n","    results[\"fpr Minority\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Minority\"][[\"fpr\"]].values[0][0]\n","    results[\"fpr Majority\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Majority\"][[\"fpr\"]].values[0][0]\n","\n","    # Store the results in the runs variable\n","    #prev_runs = runs.get(dataset_name, [])\n","    #prev_runs.append(results)\n","    runs[dataset_name] = results\n","    \"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Fl4xupge42v","executionInfo":{"status":"ok","timestamp":1690998371704,"user_tz":300,"elapsed":2584833,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"bc92f767-5d85-4364-cb85-bfe3ae29aadf"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Examples for TypeI:\n","    Total: 794989\n","    Positive: 8151 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 2ms/step\n","\n","\n","\n","Examples for TypeII:\n","    Total: 794988\n","    Positive: 8150 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 3ms/step\n","\n","\n","\n","Examples for TypeIII:\n","    Total: 794989\n","    Positive: 8151 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 2ms/step\n","\n","\n","\n","Examples for TypeIV:\n","    Total: 794989\n","    Positive: 8151 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 2ms/step\n","\n","\n","\n","Examples for TypeV:\n","    Total: 794990\n","    Positive: 8152 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 2ms/step\n","\n","\n","\n","Examples for TypeVI:\n","    Total: 794990\n","    Positive: 8152 (1.03% of total)\n","\n","\n","\n","101/101 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["#print(f\"{len(X_test['income'])}, {len(preds_binary)}, {len(y_test.values)}\")\n","#print(f\"{type(X_test['income'])}, {type(preds_binary)}, {type(y_test.values)}\")"],"metadata":{"id":"t5Y-P8p-0Cde","executionInfo":{"status":"ok","timestamp":1690995663643,"user_tz":300,"elapsed":248,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["tf_runs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsxMraWsMiqN","executionInfo":{"status":"ok","timestamp":1690998547932,"user_tz":300,"elapsed":213,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"3a080a20-b511-4b1d-f05e-d5edaa11e272"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'TypeI': {'loss': 0.07438496500253677,\n","  'cross entropy': 0.07438496500253677,\n","  'Brier score': 0.013854006305336952,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202133.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859617352485657,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5,\n","  'prc': 0.014038271270692348},\n"," 'TypeII': {'loss': 0.07432568818330765,\n","  'cross entropy': 0.07432568818330765,\n","  'Brier score': 0.013852769508957863,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202133.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859617352485657,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5,\n","  'prc': 0.014038271270692348},\n"," 'TypeIII': {'loss': 0.07446231693029404,\n","  'cross entropy': 0.07446231693029404,\n","  'Brier score': 0.013855586759746075,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202133.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859617352485657,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5,\n","  'prc': 0.014038271270692348},\n"," 'TypeIV': {'loss': 0.07455934584140778,\n","  'cross entropy': 0.07455934584140778,\n","  'Brier score': 0.013857531361281872,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202133.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859617352485657,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5,\n","  'prc': 0.014038271270692348},\n"," 'TypeV': {'loss': 0.07442189753055573,\n","  'cross entropy': 0.07442189753055573,\n","  'Brier score': 0.013854707591235638,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202134.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859617948532104,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5000148415565491,\n","  'prc': 0.014038613066077232},\n"," 'TypeVI': {'loss': 0.07444384694099426,\n","  'cross entropy': 0.07444384694099426,\n","  'Brier score': 0.013855278491973877,\n","  'tp': 0.0,\n","  'fp': 0.0,\n","  'tn': 202132.0,\n","  'fn': 2878.0,\n","  'accuracy': 0.9859616756439209,\n","  'precision': 0.0,\n","  'recall': 0.0,\n","  'auc': 0.5,\n","  'prc': 0.014038339257240295}}"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# Create a dataframe with the results for each model in each dataset.\n","rs_results = pd.DataFrame(runs)"],"metadata":{"id":"TJe6PT6De7lX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper method to obtain the metric values for a given model.\n","def get_results(results, variant, metric):\n","    col = results[variant]\n","    values = []\n","    for idx, val in col.iteritems():\n","        values.append(val[metric])\n","    return values"],"metadata":{"id":"xNvONgFnlxwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtain the relevant metrics to plots from the dataframe.\n","variants = list(datasets_paths.keys())\n","\n","plot_results = {\"Variant\": [], \"Recall\": [], \"FPR Ratio\": []}\n","\n","print(rs_results.head(10))\n","print(type(rs_results))\n","\n","for variant in variants:\n","    plot_results[\"Recall\"] += get_results(rs_results, variant, \"recall\")\n","    # Obtain the FPR if both groups.\n","    for fpr_majority, fpr_minority in zip(get_results(rs_results, variant, \"fpr Majority\"), get_results(rs_results, variant, \"fpr Minority\")):\n","        # Calculate FPR ratio as higher fpr / lower fpr\n","        if fpr_majority > fpr_minority:\n","            plot_results[\"FPR Ratio\"] += [fpr_minority/fpr_majority]\n","        else:\n","            plot_results[\"FPR Ratio\"] += [fpr_majority/fpr_minority]\n","    plot_results[\"Variant\"] += [variant] * len(get_results(rs_results, variant, \"recall\"))\n","\n","# Create a dataframe for easier plots.\n","plot_results = pd.DataFrame(plot_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"6YcvxyfmrpU0","executionInfo":{"status":"error","timestamp":1690821703468,"user_tz":300,"elapsed":8,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"47e1a5ef-d52b-4f8d-891e-6055c8c4bc74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                 TypeI  TypeII  TypeIII  TypeIV  TypeV  TypeVI\n","recall             0.0     0.0      0.0     0.0    0.0     0.0\n","recall Minority    0.0     0.0      0.0     0.0    0.0     0.0\n","recall Majority    0.0     0.0      0.0     0.0    0.0     0.0\n","fpr Minority       0.0     0.0      0.0     0.0    0.0     0.0\n","fpr Majority       0.0     0.0      0.0     0.0    0.0     0.0\n","<class 'pandas.core.frame.DataFrame'>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-28-cba141fa4293>:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n","  for idx, val in col.iteritems():\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-31dfd9ca57f1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvariant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplot_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Obtain the FPR if both groups.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfpr_majority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_minority\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fpr Majority\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fpr Minority\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-cba141fa4293>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(results, variant, metric)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"]}]},{"cell_type":"code","source":["# Create a plot with the full results of the random search algorithm.\n","sns.set()\n","sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\"})\n","\n","sns.jointplot(data=plot_results, x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\")\n","plt.ylim((0,1));\n","plt.xlim((0,1));"],"metadata":{"id":"Oqm6Udz4rv0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the final plot. Highlight the top models:\n","top_model_base = plot_results.loc[plot_results['Variant'] == 'Base'].sort_values('Recall', ascending=False).index.values\n","top_model = copy.deepcopy(top_model_base)\n","top_model = np.r_[top_model, top_model_base + (100)]\n","\n","plot_results['index'] = plot_results.index\n","plot_results['is_top'] = plot_results.apply(lambda x: 1 if x['index'] in top_model else 0, axis=1)"],"metadata":{"id":"_cqB3ppzuFJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\", \"grid.alpha\":0.1})\n","DPI = 200\n","plt.rcParams['figure.dpi'] = DPI\n","plt.rcParams['figure.figsize'] = (10,5)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2)\n","\n","# LEFT PLOT\n","sns.scatterplot(ax=ax1, data=plot_results.loc[(~plot_results.index.isin(top_model)), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2)\n","sns.scatterplot(ax=ax1, data=plot_results.loc[plot_results.index.isin(top_model), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", legend=False)\n","ax1.set(\n","    ylim=(0,1),\n","    xlim=(0,1)\n",")\n","\n","# RIGHT PLOT\n","sns.scatterplot(ax=ax2, data=plot_results.loc[(~plot_results.index.isin(top_model)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2, palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n","sns.scatterplot(ax=ax2, data=plot_results.loc[(plot_results.index.isin(top_model)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n","ax2.set(\n","    ylim=(0,0.4),\n","    ylabel=\"\",\n","    xticks=np.arange(0.2, 0.8, 0.1),\n","    yticks=np.arange(0, 0.5, 0.1),\n","    xlim=(0.2, 0.6),\n",")\n","\n","rect = plt.Rectangle((0.2, 0.004), 0.4, 0.396, facecolor=(0.1, 0.1, 0.1, 0.05), edgecolor=\"grey\", linestyle=\"-\")\n","ax1.add_patch(rect)\n","handles, labels = ax1.get_legend_handles_labels()\n","handles = list(handles) + [rect]\n","labels = list(labels) + [\"Plot on the right\"]\n","ax1.legend(handles, labels, title=\"Variant\")\n","\n","sns.move_legend(\n","    ax1,\n","    loc=\"lower center\",\n","    bbox_to_anchor=[1.08, -0.32],\n","    ncol=7\n",")"],"metadata":{"id":"dlq62-JLrxn8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8gWropi-lx5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F_5zv0M8lyCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encode the categorical variables in the datasets to integers.\n","\n","for name in datasets.keys():  # For each dataset in the suite\n","    train = train_dfs[name]\n","    test = test_dfs[name]\n","\n","    for feat in categorical_features:\n","        encoder = LabelEncoder()\n","        encoder.fit(train[feat])  # Fit an encoder to the train set.\n","        train[feat] = encoder.transform(train[feat])  # Transform train set.\n","        test[feat] = encoder.transform(test[feat])    # Transform test set."],"metadata":{"id":"zoN68qnvXxtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for dataset_name in datasets.keys():  # Run hyperparameters on all variants of datastes.\n","    X_train = train_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n","    y_train = train_dfs[dataset_name][\"fraud_bool\"]\n","    X_test = test_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n","    y_test = test_dfs[dataset_name][\"fraud_bool\"]\n","\n","    # make model training call with X_train\n","\n","\n","    # test with X_test\n","\n","    # output metrics\n"],"metadata":{"id":"DGtHhkP9X1He"},"execution_count":null,"outputs":[]}]}